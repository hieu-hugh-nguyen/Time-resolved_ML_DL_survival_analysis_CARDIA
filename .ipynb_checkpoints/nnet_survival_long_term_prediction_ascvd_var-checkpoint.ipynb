{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n_features = 'ascvd'\n",
    "term_pred = 'long_term'\n",
    "data_file_name = 'data_after_y10_origin_at_10_ascvd'\n",
    "endpt = 16\n",
    "eval_times = 365.25*np.r_[np.arange(2, endpt+1, 2)]\n",
    "training_id_file_name = 'all_training_ID_outerloop_cohort_10_26'\n",
    "work_dir = '/home/idies/workspace/Storage/hnguye78/persistent/CARDIA_project/cvd_outcome_rerun'\n",
    "work_dir = 'U:/Hieu/CARDIA_project/CARDIA_project/cvd_outcome_rerun_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tensorflow\n",
    "# %pip install lifelines\n",
    "\n",
    "#!y | pip uninstall statsmodels \n",
    "# %pip install statsmodels==0.11.0\n",
    "\n",
    "# %pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, LSTM, GRU, Embedding, Concatenate, Conv1D, GlobalMaxPooling1D, MaxPooling1D, GlobalAveragePooling1D, BatchNormalization, TimeDistributed\n",
    "from tensorflow.keras import optimizers, layers, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "import math\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines.utils import concordance_index\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snippets_dir = work_dir+ '/code/snippet'\n",
    "snippets_dir = 'U:/Hieu/CARDIA_project/CARDIA_project/Git/Python_code/snippets'\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath(snippets_dir))\n",
    "import nnet_survival\n",
    "from cox import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = work_dir+ '/csv_files'\n",
    "\n",
    "# load data:\n",
    "data_full = pd.read_csv(load_dir+'/'+data_file_name+'.csv')\n",
    "data_full = data_full.select_dtypes(include =[np.number])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>event</th>\n",
       "      <th>time</th>\n",
       "      <th>ascvd</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>hdl</th>\n",
       "      <th>sbp</th>\n",
       "      <th>hbp.medication</th>\n",
       "      <th>smoker</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100016012504</td>\n",
       "      <td>0</td>\n",
       "      <td>5258.5</td>\n",
       "      <td>0.015689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>186.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100023004268</td>\n",
       "      <td>0</td>\n",
       "      <td>5560.5</td>\n",
       "      <td>0.003673</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>166.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100033323702</td>\n",
       "      <td>0</td>\n",
       "      <td>5381.5</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>234.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100056526386</td>\n",
       "      <td>0</td>\n",
       "      <td>5511.5</td>\n",
       "      <td>0.022868</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>199.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100061300991</td>\n",
       "      <td>0</td>\n",
       "      <td>5403.5</td>\n",
       "      <td>0.017240</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>200.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>416761219907</td>\n",
       "      <td>0</td>\n",
       "      <td>5439.5</td>\n",
       "      <td>0.004976</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>225.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4196</th>\n",
       "      <td>416771521620</td>\n",
       "      <td>0</td>\n",
       "      <td>5586.5</td>\n",
       "      <td>0.008172</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>204.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4197</th>\n",
       "      <td>416783315386</td>\n",
       "      <td>0</td>\n",
       "      <td>5563.5</td>\n",
       "      <td>0.001775</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>159.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>416796224310</td>\n",
       "      <td>0</td>\n",
       "      <td>5452.5</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>164.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>110.843678</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4199</th>\n",
       "      <td>416817227898</td>\n",
       "      <td>0</td>\n",
       "      <td>5512.5</td>\n",
       "      <td>0.025263</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>204.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4200 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  event    time     ascvd  sex  race  age  cholesterol  \\\n",
       "0     100016012504      0  5258.5  0.015689    0     0   27        186.0   \n",
       "1     100023004268      0  5560.5  0.003673    0     0   35        166.0   \n",
       "2     100033323702      0  5381.5  0.001691    0     0   28        234.0   \n",
       "3     100056526386      0  5511.5  0.022868    0     1   34        199.0   \n",
       "4     100061300991      0  5403.5  0.017240    0     1   26        200.0   \n",
       "...            ...    ...     ...       ...  ...   ...  ...          ...   \n",
       "4195  416761219907      0  5439.5  0.004976    1     0   35        225.0   \n",
       "4196  416771521620      0  5586.5  0.008172    0     1   28        204.0   \n",
       "4197  416783315386      0  5563.5  0.001775    1     0   32        159.0   \n",
       "4198  416796224310      0  5452.5  0.000524    1     1   32        164.0   \n",
       "4199  416817227898      0  5512.5  0.025263    0     1   27        204.0   \n",
       "\n",
       "       hdl         sbp  hbp.medication  smoker  diabetes  \n",
       "0     38.0  134.000000               0       1         0  \n",
       "1     43.0  112.000000               0       0         0  \n",
       "2     52.0  100.000000               0       0         0  \n",
       "3     44.0  132.000000               0       0         0  \n",
       "4     40.0  118.000000               0       1         0  \n",
       "...    ...         ...             ...     ...       ...  \n",
       "4195  57.0  120.000000               0       0         0  \n",
       "4196  76.0  106.000000               0       0         0  \n",
       "4197  58.0  120.000000               0       0         0  \n",
       "4198  55.0  110.843678               0       0         0  \n",
       "4199  43.0  140.000000               0       1         0  \n",
       "\n",
       "[4200 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training id:\n",
    "loaddir = work_dir+ '/csv_files'\n",
    "trainingid_all = pd.read_csv(loaddir+'/'+training_id_file_name+'.csv')\n",
    "\n",
    "## standardize feature space, then merge back to label space:\n",
    "feature_space = data_full.drop(['ID','event','time'], axis = 1)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(feature_space)\n",
    "scaled_feature_space = scaler.transform(feature_space)\n",
    "scaled_feature_space_df = pd.DataFrame(data=scaled_feature_space[0:,0:])\n",
    "scaled_feature_space_df.insert(0, 'ID', data_full['ID'], True)\n",
    "label = data_full.loc[:,['ID','event','time']]\n",
    "data_full = pd.merge(label, scaled_feature_space_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>event</th>\n",
       "      <th>time</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100016012504</td>\n",
       "      <td>0</td>\n",
       "      <td>5258.5</td>\n",
       "      <td>0.328559</td>\n",
       "      <td>-1.120553</td>\n",
       "      <td>-0.959853</td>\n",
       "      <td>-0.814396</td>\n",
       "      <td>0.239613</td>\n",
       "      <td>-1.105713</td>\n",
       "      <td>1.858692</td>\n",
       "      <td>-0.123404</td>\n",
       "      <td>1.596965</td>\n",
       "      <td>-0.14629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100023004268</td>\n",
       "      <td>0</td>\n",
       "      <td>5560.5</td>\n",
       "      <td>-0.169216</td>\n",
       "      <td>-1.120553</td>\n",
       "      <td>-0.959853</td>\n",
       "      <td>1.388979</td>\n",
       "      <td>-0.356702</td>\n",
       "      <td>-0.746751</td>\n",
       "      <td>0.269586</td>\n",
       "      <td>-0.123404</td>\n",
       "      <td>-0.626188</td>\n",
       "      <td>-0.14629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100033323702</td>\n",
       "      <td>0</td>\n",
       "      <td>5381.5</td>\n",
       "      <td>-0.251336</td>\n",
       "      <td>-1.120553</td>\n",
       "      <td>-0.959853</td>\n",
       "      <td>-0.538974</td>\n",
       "      <td>1.670768</td>\n",
       "      <td>-0.100620</td>\n",
       "      <td>-0.597199</td>\n",
       "      <td>-0.123404</td>\n",
       "      <td>-0.626188</td>\n",
       "      <td>-0.14629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100056526386</td>\n",
       "      <td>0</td>\n",
       "      <td>5511.5</td>\n",
       "      <td>0.625972</td>\n",
       "      <td>-1.120553</td>\n",
       "      <td>1.041826</td>\n",
       "      <td>1.113557</td>\n",
       "      <td>0.627217</td>\n",
       "      <td>-0.674959</td>\n",
       "      <td>1.714228</td>\n",
       "      <td>-0.123404</td>\n",
       "      <td>-0.626188</td>\n",
       "      <td>-0.14629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100061300991</td>\n",
       "      <td>0</td>\n",
       "      <td>5403.5</td>\n",
       "      <td>0.392802</td>\n",
       "      <td>-1.120553</td>\n",
       "      <td>1.041826</td>\n",
       "      <td>-1.089818</td>\n",
       "      <td>0.657033</td>\n",
       "      <td>-0.962128</td>\n",
       "      <td>0.702979</td>\n",
       "      <td>-0.123404</td>\n",
       "      <td>1.596965</td>\n",
       "      <td>-0.14629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>416761219907</td>\n",
       "      <td>0</td>\n",
       "      <td>5439.5</td>\n",
       "      <td>-0.115260</td>\n",
       "      <td>0.892416</td>\n",
       "      <td>-0.959853</td>\n",
       "      <td>1.388979</td>\n",
       "      <td>1.402426</td>\n",
       "      <td>0.258341</td>\n",
       "      <td>0.847443</td>\n",
       "      <td>-0.123404</td>\n",
       "      <td>-0.626188</td>\n",
       "      <td>-0.14629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4196</th>\n",
       "      <td>416771521620</td>\n",
       "      <td>0</td>\n",
       "      <td>5586.5</td>\n",
       "      <td>0.017143</td>\n",
       "      <td>-1.120553</td>\n",
       "      <td>1.041826</td>\n",
       "      <td>-0.538974</td>\n",
       "      <td>0.776296</td>\n",
       "      <td>1.622396</td>\n",
       "      <td>-0.163807</td>\n",
       "      <td>-0.123404</td>\n",
       "      <td>-0.626188</td>\n",
       "      <td>-0.14629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4197</th>\n",
       "      <td>416783315386</td>\n",
       "      <td>0</td>\n",
       "      <td>5563.5</td>\n",
       "      <td>-0.247862</td>\n",
       "      <td>0.892416</td>\n",
       "      <td>-0.959853</td>\n",
       "      <td>0.562713</td>\n",
       "      <td>-0.565412</td>\n",
       "      <td>0.330134</td>\n",
       "      <td>0.847443</td>\n",
       "      <td>-0.123404</td>\n",
       "      <td>-0.626188</td>\n",
       "      <td>-0.14629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>416796224310</td>\n",
       "      <td>0</td>\n",
       "      <td>5452.5</td>\n",
       "      <td>-0.299701</td>\n",
       "      <td>0.892416</td>\n",
       "      <td>1.041826</td>\n",
       "      <td>0.562713</td>\n",
       "      <td>-0.416334</td>\n",
       "      <td>0.114757</td>\n",
       "      <td>0.186062</td>\n",
       "      <td>-0.123404</td>\n",
       "      <td>-0.626188</td>\n",
       "      <td>-0.14629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4199</th>\n",
       "      <td>416817227898</td>\n",
       "      <td>0</td>\n",
       "      <td>5512.5</td>\n",
       "      <td>0.725199</td>\n",
       "      <td>-1.120553</td>\n",
       "      <td>1.041826</td>\n",
       "      <td>-0.814396</td>\n",
       "      <td>0.776296</td>\n",
       "      <td>-0.746751</td>\n",
       "      <td>2.292085</td>\n",
       "      <td>-0.123404</td>\n",
       "      <td>1.596965</td>\n",
       "      <td>-0.14629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4200 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  event    time         0         1         2         3  \\\n",
       "0     100016012504      0  5258.5  0.328559 -1.120553 -0.959853 -0.814396   \n",
       "1     100023004268      0  5560.5 -0.169216 -1.120553 -0.959853  1.388979   \n",
       "2     100033323702      0  5381.5 -0.251336 -1.120553 -0.959853 -0.538974   \n",
       "3     100056526386      0  5511.5  0.625972 -1.120553  1.041826  1.113557   \n",
       "4     100061300991      0  5403.5  0.392802 -1.120553  1.041826 -1.089818   \n",
       "...            ...    ...     ...       ...       ...       ...       ...   \n",
       "4195  416761219907      0  5439.5 -0.115260  0.892416 -0.959853  1.388979   \n",
       "4196  416771521620      0  5586.5  0.017143 -1.120553  1.041826 -0.538974   \n",
       "4197  416783315386      0  5563.5 -0.247862  0.892416 -0.959853  0.562713   \n",
       "4198  416796224310      0  5452.5 -0.299701  0.892416  1.041826  0.562713   \n",
       "4199  416817227898      0  5512.5  0.725199 -1.120553  1.041826 -0.814396   \n",
       "\n",
       "             4         5         6         7         8        9  \n",
       "0     0.239613 -1.105713  1.858692 -0.123404  1.596965 -0.14629  \n",
       "1    -0.356702 -0.746751  0.269586 -0.123404 -0.626188 -0.14629  \n",
       "2     1.670768 -0.100620 -0.597199 -0.123404 -0.626188 -0.14629  \n",
       "3     0.627217 -0.674959  1.714228 -0.123404 -0.626188 -0.14629  \n",
       "4     0.657033 -0.962128  0.702979 -0.123404  1.596965 -0.14629  \n",
       "...        ...       ...       ...       ...       ...      ...  \n",
       "4195  1.402426  0.258341  0.847443 -0.123404 -0.626188 -0.14629  \n",
       "4196  0.776296  1.622396 -0.163807 -0.123404 -0.626188 -0.14629  \n",
       "4197 -0.565412  0.330134  0.847443 -0.123404 -0.626188 -0.14629  \n",
       "4198 -0.416334  0.114757  0.186062 -0.123404 -0.626188 -0.14629  \n",
       "4199  0.776296 -0.746751  2.292085 -0.123404  1.596965 -0.14629  \n",
       "\n",
       "[4200 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = data_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide on number of dicrete times:\n",
    "#halflife=13.*365.25\n",
    "\n",
    "#breaks = 365.25*np.r_[1, np.arange(2, endpt+1, 0.5)]\n",
    "breaks = 365.25*np.arange(1, endpt,0.5)\n",
    "#breaks=-np.log(1-np.arange(0.0,0.96,0.05))*halflife/np.log(2) \n",
    "n_intervals=len(breaks)-1\n",
    "timegap = breaks[1:] - breaks[:-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize hyperparam:\n",
    "hidden_layers_sizes = 4\n",
    "n_epochs = 50000\n",
    "learning_rate = 0.001\n",
    "lr_decay = 0.001\n",
    "momentum = 0.9\n",
    "n_in = data_full.shape[1]-3 # number of features\n",
    "\n",
    "\n",
    "def nnet_pred_surv(y_pred, breaks, fu_time):\n",
    "#Predicted survival probability from Nnet-survival model\n",
    "#Inputs are Numpy arrays.\n",
    "#y_pred: Rectangular array, each individual's conditional probability of surviving each time interval\n",
    "#breaks: Break-points for time intervals used for Nnet-survival model, starting with 0\n",
    "#fu_time: Follow-up time point at which predictions are needed\n",
    "#\n",
    "#Returns: predicted survival probability for each individual at specified follow-up time\n",
    "  y_pred=np.cumprod(y_pred, axis=1)\n",
    "  pred_surv = []\n",
    "  for i in range(y_pred.shape[0]):\n",
    "    pred_surv.append(np.interp(fu_time,breaks[1:],y_pred[i,:]))\n",
    "  return np.array(pred_surv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cross validation:\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# n_folds = 10\n",
    "# kf=StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=0)\n",
    "# early_stopping = EarlyStopping(monitor='loss', patience=20)\n",
    "\n",
    "# #l2_array = np.concatenate(([0.],np.power(10.,np.arange(-6,-2))))\n",
    "# l2_array = np.power(10.,np.arange(-3,2))\n",
    "# grid_search_train = np.zeros((len(l2_array),n_folds))\n",
    "# grid_search_test = np.zeros((len(l2_array),n_folds))\n",
    "# grid_search_c_index_train = np.zeros((len(l2_array),n_folds))\n",
    "# grid_search_c_index_test = np.zeros((len(l2_array),n_folds))\n",
    "\n",
    "# fold = 24\n",
    "# print('')\n",
    "# print('FOLD '+str(fold)+':')\n",
    "# print('')\n",
    "\n",
    "# trainingid = trainingid_all.iloc[:,fold]\n",
    "# trainingid = trainingid[~np.isnan(trainingid)]\n",
    "# eligible_id = data_full['ID'][data_full['ID'].isin(trainingid)]\n",
    "# train_df = data_full.loc[data_full['ID'].isin(eligible_id),:]\n",
    "# del train_df['ID']\n",
    "# test_df = data_full.loc[~data_full['ID'].isin(eligible_id),:]\n",
    "# del test_df['ID']\n",
    "\n",
    "# for i in range(len(l2_array)):\n",
    "#     #i = 0\n",
    "#     j=0\n",
    "#     cv_folds = kf.split(train_df.values, train_df[['event']].values)\n",
    "#     for traincv, testcv in cv_folds:\n",
    "#         print('i in len(l2_array)=' + str(i+1) + '/' + str(len(l2_array)))\n",
    "#         print('cv fold =' + str(j+1) + '/' + str(n_folds))\n",
    "#         x_train_cv = featurespace_train_df.iloc[traincv].values\n",
    "#         y_train_cv = y_train[traincv]\n",
    "#         x_test_cv = featurespace_train_df.iloc[testcv].values\n",
    "#         y_test_cv = y_train[testcv]\n",
    "\n",
    "#         model = Sequential()\n",
    "#         #model.add(Dense(n_intervals,input_dim=x_train.shape[1],bias_initializer='zeros',kernel_regularizer=regularizers.l2(l2_array[i])))\n",
    "#         model.add(Dense(hidden_layers_sizes\n",
    "#                   , input_dim=featurespace_train.shape[1]\n",
    "#                   , bias_initializer='zeros'\n",
    "#                   , activation='relu'\n",
    "#                   , kernel_regularizer=regularizers.l2(l2_array[i])\n",
    "#                   ))\n",
    "#         model.add(Dense(n_intervals))\n",
    "#         model.add(Activation('sigmoid'))\n",
    "#         model.compile(loss=nnet_survival.surv_likelihood(n_intervals)\n",
    "#                       , optimizer=optimizers.Adam()) #lr=0.0001))\n",
    "#         history=model.fit(x_train_cv, y_train_cv\n",
    "#                     , batch_size=256\n",
    "#                     , epochs=1000\n",
    "#                     , callbacks=[early_stopping]\n",
    "#                     , verbose=1\n",
    "#                     , validation_data=(x_test_cv, y_test_cv))\n",
    "#         grid_search_train[i,j] = model.evaluate(x_train_cv,y_train_cv,verbose=0)\n",
    "#         grid_search_test[i,j] = model.evaluate(x_test_cv,y_test_cv,verbose=0)\n",
    "              \n",
    "#         #Discrimination performance\n",
    "#         # y_pred is conditional prob of survival within each time interval\n",
    "#         y_pred_train_cv = model.predict_proba(x_train_cv ,verbose=0)\n",
    "#         yr26_surv_train_cv = nnet_pred_surv(y_pred_train_cv, breaks, 365.25*26)\n",
    "#         y_pred_test_cv=model.predict_proba(x_test_cv ,verbose=0)\n",
    "#         yr26_surv_test_cv = nnet_pred_surv(y_pred_test_cv, breaks, 365.25*26)\n",
    "        \n",
    "#         grid_search_c_index_train[i,j] = concordance_index(train_df.time.iloc[traincv], yr26_surv_train_cv, train_df.event.iloc[traincv])\n",
    "#         grid_search_c_index_test[i,j] = concordance_index(train_df.time.iloc[testcv], yr26_surv_test_cv, train_df.event.iloc[testcv])\n",
    "        \n",
    "#         print(' ')\n",
    "#         print('Looking at  i=' + str(i+1) + '/' + str(len(l2_array)) + (' and cv fold =' + str(j+1) + '/' + str(n_folds)))      \n",
    "#         print('Loss Train, Loss Valid, C-index Train, C-index Test:')\n",
    "#         print(grid_search_train[i,j])\n",
    "#         print(grid_search_test[i,j])\n",
    "#         print(grid_search_c_index_train[i,j])\n",
    "#         print(grid_search_c_index_test[i,j]) \n",
    "#         print(' ')\n",
    "              \n",
    "#         j=j+1\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "# print('grid_search_train:')\n",
    "# print(grid_search_train)\n",
    "# print('grid_search_test:')\n",
    "# print(grid_search_test)\n",
    "# print(np.average(grid_search_train,axis=1))\n",
    "# print(np.average(grid_search_test,axis=1))\n",
    "# print(grid_search_c_index_train)\n",
    "# print(grid_search_c_index_test)\n",
    "\n",
    "# l2_final = l2_array[np.argmax(-np.average(grid_search_test,axis=1))]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 0:\n",
      "\n",
      "Train C-index fold 1 :\n",
      "0.7387079281463321\n",
      "Test C-index fold 1 :\n",
      "0.7576541612764123\n",
      "\n",
      "FOLD 1:\n",
      "\n",
      "Train C-index fold 2 :\n",
      "0.7508210208613162\n",
      "Test C-index fold 2 :\n",
      "0.7332389560419615\n",
      "\n",
      "FOLD 2:\n",
      "\n",
      "Train C-index fold 3 :\n",
      "0.756069061658328\n",
      "Test C-index fold 3 :\n",
      "0.7061643322597558\n",
      "\n",
      "FOLD 3:\n",
      "\n",
      "Train C-index fold 4 :\n",
      "0.7360094992369128\n",
      "Test C-index fold 4 :\n",
      "0.7824517512508935\n",
      "\n",
      "FOLD 4:\n",
      "\n",
      "Train C-index fold 5 :\n",
      "0.7734319503797997\n",
      "Test C-index fold 5 :\n",
      "0.6917378293555215\n",
      "\n",
      "FOLD 5:\n",
      "\n",
      "Train C-index fold 6 :\n",
      "0.7546318752804965\n",
      "Test C-index fold 6 :\n",
      "0.7106719947208271\n",
      "\n",
      "FOLD 6:\n",
      "\n",
      "Train C-index fold 7 :\n",
      "0.749020927045143\n",
      "Test C-index fold 7 :\n",
      "0.7595143167814425\n",
      "\n",
      "FOLD 7:\n",
      "\n",
      "Train C-index fold 8 :\n",
      "0.7691346036038897\n",
      "Test C-index fold 8 :\n",
      "0.661213161450535\n",
      "\n",
      "FOLD 8:\n",
      "\n",
      "Train C-index fold 9 :\n",
      "0.7535306686122257\n",
      "Test C-index fold 9 :\n",
      "0.7157910195689687\n",
      "\n",
      "FOLD 9:\n",
      "\n",
      "Train C-index fold 10 :\n",
      "0.7414970800820042\n",
      "Test C-index fold 10 :\n",
      "0.7536634934217563\n",
      "\n",
      "FOLD 10:\n",
      "\n",
      "Train C-index fold 11 :\n",
      "0.7572348913258676\n",
      "Test C-index fold 11 :\n",
      "0.7358163707232568\n",
      "\n",
      "FOLD 11:\n",
      "\n",
      "Train C-index fold 12 :\n",
      "0.7681651078246376\n",
      "Test C-index fold 12 :\n",
      "0.6648467642134381\n",
      "\n",
      "FOLD 12:\n",
      "\n",
      "Train C-index fold 13 :\n",
      "0.7431700573860691\n",
      "Test C-index fold 13 :\n",
      "0.7637581462708183\n",
      "\n",
      "FOLD 13:\n",
      "\n",
      "Train C-index fold 14 :\n",
      "0.7550079227790112\n",
      "Test C-index fold 14 :\n",
      "0.7250646371217363\n",
      "\n",
      "FOLD 14:\n",
      "\n",
      "Train C-index fold 15 :\n",
      "0.7383847062370642\n",
      "Test C-index fold 15 :\n",
      "0.7656112576956904\n",
      "\n",
      "FOLD 15:\n",
      "\n",
      "Train C-index fold 16 :\n",
      "0.7602807170747571\n",
      "Test C-index fold 16 :\n",
      "0.6897911916910939\n",
      "\n",
      "FOLD 16:\n",
      "\n",
      "Train C-index fold 17 :\n",
      "0.7555558587505486\n",
      "Test C-index fold 17 :\n",
      "0.7407809896399333\n",
      "\n",
      "FOLD 17:\n",
      "\n",
      "Train C-index fold 18 :\n",
      "0.752808963362527\n",
      "Test C-index fold 18 :\n",
      "0.6982263857518421\n",
      "\n",
      "FOLD 18:\n",
      "\n",
      "Train C-index fold 19 :\n",
      "0.7509125059191104\n",
      "Test C-index fold 19 :\n",
      "0.7445346658338539\n",
      "\n",
      "FOLD 19:\n",
      "\n",
      "Train C-index fold 20 :\n",
      "0.7456688042041535\n",
      "Test C-index fold 20 :\n",
      "0.7684052907412029\n",
      "\n",
      "FOLD 20:\n",
      "\n",
      "Train C-index fold 21 :\n",
      "0.7604320410917478\n",
      "Test C-index fold 21 :\n",
      "0.6911786674634001\n",
      "\n",
      "FOLD 21:\n",
      "\n",
      "Train C-index fold 22 :\n",
      "0.7414033856877744\n",
      "Test C-index fold 22 :\n",
      "0.7551043012737678\n",
      "\n",
      "FOLD 22:\n",
      "\n",
      "Train C-index fold 23 :\n",
      "0.7402338245588516\n",
      "Test C-index fold 23 :\n",
      "0.7848124229010958\n",
      "\n",
      "FOLD 23:\n",
      "\n",
      "Train C-index fold 24 :\n",
      "0.7600074673247627\n",
      "Test C-index fold 24 :\n",
      "0.6876665946257474\n",
      "\n",
      "FOLD 24:\n",
      "\n",
      "Train C-index fold 25 :\n",
      "0.7474517934705497\n",
      "Test C-index fold 25 :\n",
      "0.7483902922238732\n"
     ]
    }
   ],
   "source": [
    "# Outerloop:\n",
    "for fold in range(25):\n",
    "\n",
    "    ## fold = 24\n",
    "    print('')\n",
    "    print('FOLD '+str(fold)+':')\n",
    "    print('')\n",
    "\n",
    "    trainingid = trainingid_all.iloc[:,fold]\n",
    "    trainingid = trainingid[~np.isnan(trainingid)]\n",
    "    eligible_id = data_full['ID'][data_full['ID'].isin(trainingid)]\n",
    "    train_df = data_full.loc[data_full['ID'].isin(eligible_id),:]\n",
    "    del train_df['ID']\n",
    "    test_df = data_full.loc[~data_full['ID'].isin(eligible_id),:]\n",
    "    del test_df['ID']\n",
    "\n",
    "\n",
    "    # reformat the train and test set:\n",
    "    y_train = nnet_survival.make_surv_array(train_df.time.values\n",
    "                                            , train_df.event.values\n",
    "                                            , breaks)\n",
    "    y_test = nnet_survival.make_surv_array(test_df.time.values\n",
    "                                           , test_df.event.values\n",
    "                                           , breaks)\n",
    "    featurespace_train_df = train_df.drop(['time','event'],axis =1)\n",
    "    featurespace_test_df = test_df.drop(['time','event'],axis =1)\n",
    "\n",
    "    featurespace_train = train_df.drop(['time','event'],axis =1).values\n",
    "    featurespace_test = test_df.drop(['time','event'],axis =1).values\n",
    "\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    # Build model:\n",
    "    l2_final=0.1\n",
    "\n",
    "    from numpy.random import seed\n",
    "\n",
    "    seed(1)\n",
    "    import tensorflow as tf\n",
    "    import keras\n",
    "    tf.random.set_seed(2)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layers_sizes\n",
    "                    , input_dim=featurespace_train.shape[1]\n",
    "                    , bias_initializer='zeros'\n",
    "                    , kernel_regularizer=regularizers.l2(l2_final)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(n_intervals))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    # import keras.backend.tensorflow_backend as kk\n",
    "\n",
    "    model.compile(loss=nnet_survival.surv_likelihood(n_intervals), optimizer=optimizers.RMSprop())\n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=20)\n",
    "    history=model.fit(featurespace_train, y_train, batch_size=4063, epochs=100000\n",
    "                      , callbacks=[early_stopping]\n",
    "                      , verbose=0)\n",
    "\n",
    "\n",
    "    # print loss of train and valid data:\n",
    "    # print(model.evaluate(featurespace_train,y_train,verbose=0))\n",
    "    # model.evaluate(featurespace_test,y_test,verbose=0)\n",
    "\n",
    "    #Discrimination performance\n",
    "    # y_pred is conditional prob of survival within each time interval\n",
    "    y_pred_train = model.predict(featurespace_train,verbose=0)\n",
    "    # cumprod = cumulative product, the probability of surviving from time 0 up to the time interval of interest\n",
    "    # index -1 because we are interested in -1 \n",
    "    last_yr_surv_train=np.cumprod(y_pred_train[:,0:np.nonzero(breaks>365*(endpt-1))[0][0]], axis=1)[:,-1]\n",
    "    print('Train C-index fold', str(fold+1),':')\n",
    "    print(concordance_index(train_df.time, last_yr_surv_train, train_df.event)) \n",
    "\n",
    "    y_pred=model.predict(featurespace_test,verbose=0)\n",
    "    last_yr_surv=np.cumprod(y_pred[:,0:np.nonzero(breaks>365*(endpt-1))[0][0]], axis=1)[:,-1]\n",
    "    print('Test C-index fold', str(fold+1),':')\n",
    "    print(concordance_index(test_df.time,last_yr_surv, test_df.event))\n",
    "\n",
    "    pred_surv = np.zeros((len(test_df.event), len(eval_times)))\n",
    "    col=0\n",
    "    for time in eval_times:\n",
    "        pred_surv[:,col] = nnet_pred_surv(y_pred, breaks, time)\n",
    "        col = col+1\n",
    "    pred_surv = pd.DataFrame(data = pred_surv)\n",
    "    # savedir = os.path.join(os.getcwd(),'python_files/csv_files/nnet_survival/all_features')\n",
    "    savedir = os.path.join(work_dir,'csv_files/nnet_survival/'+str(n_features)+'_features/'+term_pred)\n",
    "    try: \n",
    "        os.makedirs(savedir)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(savedir):\n",
    "            raise\n",
    "    actual_fold = fold+1\n",
    "    pred_surv.to_csv(savedir+'/pred_prob_surv_fold_'+str(actual_fold)+'.csv', index = None, header = True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cross validation:\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# n_folds = 10\n",
    "# kf=StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=0)\n",
    "# early_stopping = EarlyStopping(monitor='loss', patience=20)\n",
    "\n",
    "# #l2_array = np.concatenate(([0.],np.power(10.,np.arange(-6,-2))))\n",
    "# l2_array = np.power(10.,np.arange(-3,2))\n",
    "# grid_search_train = np.zeros((len(l2_array),n_folds))\n",
    "# grid_search_test = np.zeros((len(l2_array),n_folds))\n",
    "# grid_search_c_index_train = np.zeros((len(l2_array),n_folds))\n",
    "# grid_search_c_index_test = np.zeros((len(l2_array),n_folds))\n",
    "\n",
    "# for i in range(len(l2_array)):\n",
    "#     #i = 0\n",
    "#     j=0\n",
    "#     cv_folds = kf.split(train_df.values, train_df[['event']].values)\n",
    "#     for traincv, testcv in cv_folds:\n",
    "#         print('i in len(l2_array)=' + str(i+1) + '/' + str(len(l2_array)))\n",
    "#         print('cv fold =' + str(j+1) + '/' + str(n_folds))\n",
    "#         x_train_cv = featurespace_train_df.iloc[traincv].values\n",
    "#         y_train_cv = y_train[traincv]\n",
    "#         x_test_cv = featurespace_train_df.iloc[testcv].values\n",
    "#         y_test_cv = y_train[testcv]\n",
    "\n",
    "#         model = Sequential()\n",
    "#         #model.add(Dense(n_intervals,input_dim=x_train.shape[1],bias_initializer='zeros',kernel_regularizer=regularizers.l2(l2_array[i])))\n",
    "#         model.add(Dense(hidden_layers_sizes\n",
    "#                   , input_dim=featurespace_train.shape[1]\n",
    "#                   , bias_initializer='zeros'\n",
    "#                   , activation='relu'\n",
    "#                   , kernel_regularizer=regularizers.l2(l2_array[i])\n",
    "#                   ))\n",
    "#         model.add(Dense(n_intervals))\n",
    "#         model.add(Activation('sigmoid'))\n",
    "#         model.compile(loss=nnet_survival.surv_likelihood(n_intervals)\n",
    "#                       , optimizer=optimizers.Adam()) #lr=0.0001))\n",
    "#         history=model.fit(x_train_cv, y_train_cv\n",
    "#                     , batch_size=256\n",
    "#                     , epochs=1000\n",
    "#                     , callbacks=[early_stopping]\n",
    "#                     , verbose=1\n",
    "#                     , validation_data=(x_test_cv, y_test_cv))\n",
    "#         grid_search_train[i,j] = model.evaluate(x_train_cv,y_train_cv,verbose=0)\n",
    "#         grid_search_test[i,j] = model.evaluate(x_test_cv,y_test_cv,verbose=0)\n",
    "              \n",
    "#         #Discrimination performance\n",
    "#         # y_pred is conditional prob of survival within each time interval\n",
    "#         y_pred_train_cv = model.predict_proba(x_train_cv ,verbose=0)\n",
    "#         yr26_surv_train_cv = nnet_pred_surv(y_pred_train_cv, breaks, 365.25*26)\n",
    "#         y_pred_test_cv=model.predict_proba(x_test_cv ,verbose=0)\n",
    "#         yr26_surv_test_cv = nnet_pred_surv(y_pred_test_cv, breaks, 365.25*26)\n",
    "        \n",
    "#         grid_search_c_index_train[i,j] = concordance_index(train_df.time.iloc[traincv], yr26_surv_train_cv, train_df.event.iloc[traincv])\n",
    "#         grid_search_c_index_test[i,j] = concordance_index(train_df.time.iloc[testcv], yr26_surv_test_cv, train_df.event.iloc[testcv])\n",
    "        \n",
    "#         print(' ')\n",
    "#         print('Looking at  i=' + str(i+1) + '/' + str(len(l2_array)) + (' and cv fold =' + str(j+1) + '/' + str(n_folds)))      \n",
    "#         print('Loss Train, Loss Valid, C-index Train, C-index Test:')\n",
    "#         print(grid_search_train[i,j])\n",
    "#         print(grid_search_test[i,j])\n",
    "#         print(grid_search_c_index_train[i,j])\n",
    "#         print(grid_search_c_index_test[i,j]) \n",
    "#         print(' ')\n",
    "              \n",
    "#         j=j+1\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "# print('grid_search_train:')\n",
    "# print(grid_search_train)\n",
    "# print('grid_search_test:')\n",
    "# print(grid_search_test)\n",
    "# print(np.average(grid_search_train,axis=1))\n",
    "# print(np.average(grid_search_test,axis=1))\n",
    "# print(grid_search_c_index_train)\n",
    "# print(grid_search_c_index_test)\n",
    "#\n",
    "#l2_final = l2_array[np.argmax(-np.average(grid_search_test,axis=1))]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ##########################\n",
    "# # Build model with tuned hyperparam:\n",
    "# l2_final=0.0001\n",
    "\n",
    "# from numpy.random import seed\n",
    "\n",
    "# seed(1)\n",
    "# import tensorflow as tf\n",
    "# import keras\n",
    "# tf.random.set_seed(2)\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(hidden_layers_sizes\n",
    "#                 , input_dim=featurespace_train.shape[1]\n",
    "#                 , bias_initializer='zeros'\n",
    "#                 , kernel_regularizer=regularizers.l2(l2_final)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(n_intervals))\n",
    "# model.add(Activation('sigmoid'))\n",
    "# # import keras.backend.tensorflow_backend as kk\n",
    "\n",
    "# model.compile(loss=nnet_survival.surv_likelihood(n_intervals), optimizer=optimizers.RMSprop())\n",
    "# early_stopping = EarlyStopping(monitor='loss', patience=20)\n",
    "# history=model.fit(featurespace_train, y_train, batch_size=4063, epochs=100000\n",
    "#                   , callbacks=[early_stopping]\n",
    "#                   , verbose=0)\n",
    "\n",
    "\n",
    "# # print loss of train and valid data:\n",
    "# # print(model.evaluate(featurespace_train,y_train,verbose=0))\n",
    "# # model.evaluate(featurespace_test,y_test,verbose=0)\n",
    "\n",
    "# #Discrimination performance\n",
    "# # y_pred is conditional prob of survival within each time interval\n",
    "# y_pred_train = model.predict(featurespace_train,verbose=0)\n",
    "# # cumprod = cumulative product, the probability of surviving from time 0 up to the time interval of interest\n",
    "# # index -1 because we are interested in -1 \n",
    "# last_yr_surv_train=np.cumprod(y_pred_train[:,0:np.nonzero(breaks>365*(endpt-1))[0][0]], axis=1)[:,-1]\n",
    "# print('Train C-index fold', str(fold+1),':')\n",
    "# print(concordance_index(train_df.time, last_yr_surv_train, train_df.event)) \n",
    "\n",
    "# y_pred=model.predict(featurespace_test,verbose=0)\n",
    "# last_yr_surv=np.cumprod(y_pred[:,0:np.nonzero(breaks>365*(endpt-1))[0][0]], axis=1)[:,-1]\n",
    "# print('Test C-index fold', str(fold+1),':')\n",
    "# print(concordance_index(test_df.time,last_yr_surv, test_df.event))\n",
    "\n",
    "# pred_surv = np.zeros((len(test_df.event), len(eval_times)))\n",
    "# col=0\n",
    "# for time in eval_times:\n",
    "#     pred_surv[:,col] = nnet_pred_surv(y_pred, breaks, time)\n",
    "#     col = col+1\n",
    "# pred_surv = pd.DataFrame(data = pred_surv)\n",
    "# # savedir = os.path.join(os.getcwd(),'python_files/csv_files/nnet_survival/all_features')\n",
    "# savedir = os.path.join(work_dir,'csv_files/nnet_survival/'+str(n_features)+'_features/'+term_pred)\n",
    "# try: \n",
    "#     os.makedirs(savedir)\n",
    "# except OSError:\n",
    "#     if not os.path.isdir(savedir):\n",
    "#         raise\n",
    "# actual_fold = fold+1\n",
    "# pred_surv.to_csv(savedir+'/pred_prob_surv_fold_'+str(actual_fold)+'.csv', index = None, header = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
